# k-means clustering

**Кластеризация** — задача группировки множества объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров по какому-либо критерию.

![Clusters](https://user-images.githubusercontent.com/18848039/86250490-5190a800-bbb9-11ea-8718-29309309483d.png)

**Метод k-средних (k-means)** - один из алгоритмов машинного обучения, решающий задачу кластеризации. Данные произвольно разбиваются на кластеры, после чего итеративно перевычисляется центр масс для каждого кластера, полученного на предыдущем шаге, затем векторы разбиваются на кластеры вновь в соответствии с тем, какой из новых центров оказался ближе по выбранной метрике. Цель алгоритма заключается в разделении **n** наблюдений на **k** кластеров таким образом, чтобы каждое наблюдение принадлежало ровно одному кластеру, расположенному на наименьшем расстоянии от наблюдения.

![k-means](https://user-images.githubusercontent.com/18848039/86251509-a254d080-bbba-11ea-8122-2c602a8001cc.jpg)

В каждой итерации **k-means** нам нужен способ найти ближайший центроид к каждому элементу набора данных. Одним из простейших способов вычисления расстояния между двумя векторами признаков является использование евклидова расстояния. Евклидово расстояние между двумя векторами типа [p1, q1] и [p2, q2] равно:

![Euclade_distance2](https://user-images.githubusercontent.com/18848039/86250118-d929e700-bbb8-11ea-8aaf-c4d20a79c40a.PNG)

Шаг 1 – Нужно указать количество кластеров **k**, которые должны быть сгенерированы этим алгоритмом.

Шаг 2 – Затем случайным образом выберается K точек данных и назначает каждую точку данных кластеру. Проще говоря, классифицировать данные на основе количества точек данных.

Шаг 3 – Теперь алгоритм будет вычислять кластерные центроиды.

Шаг 4 – Далее, продолжает повторяться следующее до тех пор, пока мы не найдем оптимальный центроид, который является назначением точек данных кластерам, которые больше не меняются:

   * Сначала будет вычислена сумма квадратов расстояния между точками данных и центроидами.

   * Теперь мы должны назначить каждую точку данных кластеру, который находится ближе, чем другой кластер (центроид).

   * Наконец, вычислияются центроиды для кластеров, взяв среднее значение всех точек данных этого кластера.

![K-means_convergence](https://user-images.githubusercontent.com/18848039/86250219-fc549680-bbb8-11ea-972d-ca4e866cfeb9.gif)